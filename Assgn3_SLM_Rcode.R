#libraries needed are defined in the below section:
install.packages(c("tidyverse","caret","glmnet","car","ipred"))
library(tidyverse) #For ggplot2 and dplyr
library(caret) #Classification and Regression Training package
library(glmnet) #For visualisng correlation matrix
library(dplyr)
library(ipred) #For Bagging
library(rpart)  #For CART modelling
library(rpart.plot) #For plotting CART
library(readr)


#---------------------------------------------------------------------
#importing the data set Malware samples into the studio:

mal_df = read.csv("C:/Users/zarak/Downloads/MalwareSamples10000.csv", stringsAsFactors = TRUE)
View(mal_df)

#---------------------------------------------------------------------------
#Evaluating supervised learning models which is selected randomly with ID given

set.seed(10498091)
models.list1 <- c("Logistic Ridge Regression",
                  "Logistic LASSO Regression",
                  "Logistic Elastic-Net Regression")

models.list2 <- c("Classification Tree",
                  "Bagging Tree",
                  "Random Forest")

myModels <- c("Binary Logistic Regression",
              sample(models.list1,size=1),
              sample(models.list2,size=1))

myModels %>% data.frame

#---------------------------------------------------------------------
#Create the training and test datasets
set.seed(10498091) #Set the random seed.
# Step 1: Get row numbers for the training data
trainRowNum <- createDataPartition(mal_df$isMalware, #The outcome variable
                                   #proportion of data to form the training set
                                   p=0.80,
                                   #Don't store the result in a list
                                   list=FALSE);
# Step 2: Create the training dataset
trainData <- mal_df[trainRowNum,-1]
View(trainData)
# Step 3: Create the test dataset
testData <- mal_df[-trainRowNum,-1]
View(testData)

#--------------------------------------------------------------------------------------------

#Binary Logistic regression modelling
#--------------------------------------------------------------------
mod.malw.lg <- glm(isMalware~., family="binomial", data=trainData);
summary(mod.malw.lg) #Summarise the model

#predicted probability of isMalware on the test data
pred.prob <- predict(mod.malw.lg,new=testData,type="response")
pred.class <- ifelse(pred.prob>0.5,"Yes","No")
#Confusion matrix with re-ordering of "Yes" and "No" responses
cf.lg <- table(pred.class %>% as.factor %>% relevel(ref="Yes"),
               testData$isMalware %>% as.factor %>% relevel(ref="Yes"));
Total = sum
addmargins(round(prop.table(cf.lg,2)*100,2), FUN= Total) #Proportions by columns


#Summary of confusion matrix
confusionMatrix(cf.lg);

#----------------------------------------------------------------------
#RFE on binary logistic Regression to check the difference between optimal and it
set.seed(1)

options(warn=-1) #Turn the warning messages off

subsets <- c(3:10) #Subsets of features to test

#Set the cross validation parameters
ctrl <- rfeControl(functions = lrFuncs,
                   method = "repeatedcv", #10-fold CV by default
                   repeats = 10, #repeat CV 10 times
                   #Prevents copious amounts of output from being produced
                   verbose = FALSE)

#Perform RFE specifying the formula instead.
lrProfile <- rfe(isMalware~., #Specifying PRP as a function all other variables.
                 data=trainData[,1:11], #training data set excluding Vendor and Model
                 sizes = subsets,
                 rfeControl = ctrl)
lrProfile

#Access the optimal model and show its coefficients
lrProfile$fit

#Summarise the optimal model and show the significance of the features
summary(lrProfile$fit)

#Convert the categorical features to dummy variables, remove the first
#column and convert the whole data matrix to a data frame.
dummy.testData <- model.matrix(~.,data=testData)[,-1] %>% data.frame
View(dummy.testData)

#Predict on the test set using the optimal model
pred.optmod <- predict(lrProfile$fit,newdata=dummy.testData)
pred.optmod %>% round(digits=3) #Show prediction to 3 dp

#predicted probability of isMalware on the test data
#Here since the values are converted to dummy variables so, 0 and 1 values
#are interchanged and 0 represents here as non malware and 1 represents as malware samples
pred.prob.rfe <- predict(lrProfile$fit,new=dummy.testData,type="response")
pred.class.rfe <- ifelse(pred.prob.rfe>0.5,1,0)

#Confusion matrix with 0 as No and 1 as Yes because of dummy variables 
cf.lg.rfe <- table(pred.class.rfe,dummy.testData$isMalware); cf.lg.rfe
prop <- prop.table(cf.lg.rfe,2); prop %>% round(digit=3)*100 #Proportions by columns

#Sensitivity and Specificity
specificity <- prop[1,1] #specificity
sensitivity <- prop[2,2] #sensitivity

#Accuracy
accuracy <- sum(diag(cf.lg.rfe)) / sum(cf.lg.rfe)
c(Spec=specificity, Sens=sensitivity, Acc=accuracy) %>% round(digits = 4)*100

#------------------------------------------------------------------------------------------

#Logistic Rigde Regression - 2nd model
#As we are running ridge regression in this first instance, alpha will be set to 0 here. Furthermore, we create a
#list of 100 ?? values to search through
lambdas <- 10^seq(-3,1,length=100) #A sequence 100 lambda values
set.seed(1)
mod.malw.ridge <- train(isMalware ~., #Formula
                         data = trainData, #Training data
                         method = "glmnet", #Penalised regression modelling
                         #Set to c("center", "scale") to standardise data
                         preProcess = NULL,
                         #Perform 10-fold CV, 5 times over
                         trControl = trainControl("repeatedcv",
                                                  number = 10,
                                                  repeats = 5),
                         tuneGrid = expand.grid(alpha = 0, #Ridge regression
                                                lambda = lambdas)
)
#Optimal lambda value
mod.malw.ridge$bestTune

# Model coefficients
coef(mod.malw.ridge$finalModel, mod.malw.ridge$bestTune$lambda)  

#predicted probability of isMalware on the test data
pred.class.ridge <- predict(mod.malw.ridge,new=testData)
#Confusion matrix with re-ordering of "Yes" and "No" responses
cf.ridge <- table(pred.class.ridge %>% as.factor %>% relevel(ref="Yes"),
                  testData$isMalware %>% as.factor %>% relevel(ref="Yes"));
prop <- prop.table(cf.ridge,2); prop %>% round(digit=3)*100#Proportions by columns

Total = sum
addmargins(round(prop.table(cf.ridge,2)*100,2), FUN= Total) #Proportions by columns

#Summary of confusion matrix
confusionMatrix(cf.ridge)
#-----------------------------------------------------------------------------------------

#Bagging tree - 3rd Model to tune and optimize

## ----bc_BagTree------------------------------------------------------------------
set.seed(1)
btree.malw <- bagging(isMalware~.,
                    data=trainData,
                    nbagg=100,  
                    coob=TRUE); 
btree.malw
#Here the result we get, the OOB misclassification error is 0.2426 i.e., 24.26.
#So, in other words the OOB accuracy is 100-24.26 = 75.74.

## --------------------------------------------------------------------------------
#Summary of predictions on test set
test.pred.mal <- predict(btree.malw,newdata=testData,type="class"); 

test.cf.mal <- confusionMatrix(test.pred.mal %>% relevel(ref="Yes"),
                              testData$isMalware %>% relevel(ref="Yes"))

prop.cf <- test.cf.mal$table %>% prop.table(2) %>% round(digits = 4)*100; prop.cf


test.cf.mal

## ----bc_BagTree_Tune-------------------------------------------------------------
#Intialise the hyperparamter search grid
grid.mal <- expand.grid(nbagg=seq(25,150,25),  #A sequence of nbagg values
                       cp=seq(0,0.5,0.1),  #A sequence of cp values
                       minsplit=seq(5,20,5),  #A sequence of minsplits values
                       #Initialise columns to store the OOB misclassification rate
                       OOB.misclass=NA, 
                       #Initialise columns to store sensitivity, specificity and
                       #accuracy of bagging at each run.
                       test.sens=NA,
                       test.spec=NA,
                       test.acc=NA)  

for (I in 1:nrow(grid.mal))
{
  set.seed(123)
  
  #Perform bagging
  btree.mal <- bagging(isMalware~.,
                      data=trainData,
                      nbagg=grid.mal$nbagg[I],  
                      coob=TRUE,
                      control=rpart.control(cp=grid.mal$cp[I],
                                            minsplit=grid.mal$minsplit[I]));
  
  #OOB misclassification rate
  grid.mal$OOB.misclass[I] <- btree.mal$err*100
  
  #Summary of predictions on test set
  test.pred.mal <- predict(btree.mal,newdata=testData,type="class");  #Class prediction
  
  #Confusion matrix
  test.cf.mal <- confusionMatrix(test.pred.mal %>% relevel(ref="Yes"),
                                testData$isMalware %>% relevel(ref="Yes"))
  
  prop.cf.mal <- test.cf.mal$table %>% prop.table(2)
  grid.mal$test.sens[I] <- prop.cf.mal[1,1]*100  #Sensitivity
  grid.mal$test.spec[I] <- prop.cf.mal[2,2]*100  #Specificity
  grid.mal$test.acc[I] <- test.cf.mal$overall[1]*100  #Accuracy
}

#Sort the results by the OOB misclassification rate and display them.
grid.mal[order(grid.mal$OOB.misclass,decreasing=FALSE)[1:10],] %>% round(2)

## --------------------------------------------------------------------------------




#************************************************************************************#
#Real Email Sample Dataset:
#---------------------------

#importing the data set Malware samples into the studio:

em_test= read.csv("C:/Users/zarak/Downloads/EmailSamples50000.csv", stringsAsFactors = TRUE)
View(em_test)
em.test = em_test[,-1]
View(em.test)
#---------------------------------------------------------------------------------------
#Real test data on isMalware for email sample

#**************************************************************************#
#Binary Logistic Regression Model- RFE Algo
pred.prob.rl <- predict(mod.malw.lg,new=em.test,type="response")
pred.class.rl <- ifelse(pred.prob.rl>0.5,"Yes","No")
#Confusion matrix with re-ordering of "Yes" and "No" responses
cf.lg.rl <- table(pred.class.rl %>% as.factor %>% relevel(ref="Yes"),
               em.test$isMalware %>% as.factor %>% relevel(ref="Yes"));
prop.rl <- prop.table(cf.lg.rl,2); prop.rl %>% round(digit=3) #Proportions by columns

Total = sum
addmargins(round(prop.table(cf.lg.rl,2)*100,2), FUN= Total) #Proportions by columns

#Summary of confusion matrix
confusionMatrix(cf.lg.rl);

#For RFE on to predict on real test data
#Convert the categorical features to dummy variables, remove the first
#column and convert the whole data matrix to a data frame.
dummy.em <- model.matrix(~.,data=em.test)[,-1] %>% data.frame


#Predict on the test set using the optimal model
pred.optmod.em <- predict(lrProfile$fit,newdata=dummy.em)
pred.optmod.em %>% round(digits=3) #Show prediction to 3 dp

#predicted probability of isMalware on the test data
pred.prob.em <- predict(lrProfile$fit,new=dummy.em,type="response")
pred.class.em <- ifelse(pred.prob.em>0.5,1,0)
#Confusion matrix with re-ordering of "Yes" and "No" responses
cf.lg.rfe.em <- table(pred.class.em,dummy.em$isMalware);
prop.em <- prop.table(cf.lg.rfe.em,2); prop.em %>% round(digit=3)*100 #Proportions by columns


Total = sum
addmargins(round(prop.table(cf.lg.rfe.em,2)*100,2), FUN= Total) #Proportions by columns


#Sensitivity and Specificity
specificity.em <- prop.em[1,1] #specificity
sensitivity.em <- prop.em[2,2] #sensitivity

#Accuracy
accuracy.em <- sum(diag(cf.lg.rfe.em)) / sum(cf.lg.rfe.em)
c(Spec=specificity.em, Sens=sensitivity.em, Acc=accuracy.em) %>% round(digits = 4)*100


#**************************************************************************#
#Logistic Rigde Regression optimal solution to test real data email samples
#predicted probability of isMalware on the test data
pred.class.ridge.rl <- predict(mod.malw.ridge,new=em.test)

#Confusion matrix with re-ordering of "Yes" and "No" responses
cf.ridge.rl <- table(pred.class.ridge.rl %>% as.factor %>% relevel(ref="Yes"),
                  em.test$isMalware %>% as.factor %>% relevel(ref="Yes"));
prop.rigde.rl <- prop.table(cf.ridge,2); prop.rigde.rl %>% round(digit=3) #Proportions by columns

Total = sum
addmargins(round(prop.table(cf.ridge.rl,2)*100,2), FUN= Total) #Proportions by columns

#Summary of confusion matrix
confusionMatrix(cf.ridge.rl)
#-------------------------------------------------------------------------

#Testing real data sample on Bagging tree
#**************************************************************************#
#Summary of predictions on test set
test.pred.bc.rl <- predict(btree.malw,newdata=em.test,type="class"); 

test.cf.bc.rl <- confusionMatrix(test.pred.bc.rl %>% relevel(ref="Yes"),
                              em.test$isMalware %>% relevel(ref="Yes"))

prop.cf.rl <- test.cf.bc.rl$table %>% prop.table(2) %>% round(digits = 4)*100; prop.cf.rl

test.cf.bc.rl

## ----bc_BagTree_Tune-------------------------------------------------------------
#Intialise the hyperparamter search grid
grid.rmal <- expand.grid(nbagg=seq(25,150,25),  #A sequence of nbagg values
                       cp=seq(0,0.5,0.1),  #A sequence of cp values
                       minsplit=seq(5,20,5),  #A sequence of minsplits values
                       #Initialise columns to store the OOB misclassification rate
                       OOB.misclass=NA, 
                       #Initialise columns to store sensitivity, specificity and
                       #accuracy of bagging at each run.
                       test.sens=NA,
                       test.spec=NA,
                       test.acc=NA)  

for (I in 1:nrow(grid.rmal))
{
  set.seed(123)
  
  #Perform bagging
  btree.rmal <- bagging(isMalware~.,
                      data=trainData,
                      nbagg=grid.rmal$nbagg[I],  
                      coob=TRUE,
                      control=rpart.control(cp=grid.rmal$cp[I],
                                            minsplit=grid.rmal$minsplit[I]));
  
  #OOB misclassification rate
  grid.rmal$OOB.misclass[I] <- btree.rmal$err*100
  
  #Summary of predictions on test set
  test.pred.r1 <- predict(btree.rmal,newdata=em.test,type="class");  #Class prediction
  
  #Confusion matrix
  test.cf.r1 <- confusionMatrix(test.pred.r1 %>% relevel(ref="Yes"),
                                em.test$isMalware %>% relevel(ref="Yes"))
  
  prop.cf.r1 <- test.cf.r1$table %>% prop.table(2)
  grid.rmal$test.sens[I] <- prop.cf.r1[1,1]*100  #Sensitivity
  grid.rmal$test.spec[I] <- prop.cf.r1[2,2]*100  #Specificity
  grid.rmal$test.acc[I] <- test.cf.r1$overall[1]*100  #Accuracy
}

#Sort the results by the OOB misclassification rate and display them.
grid.rmal[order(grid.rmal$OOB.misclass,decreasing=FALSE)[1:10],] %>% round(2)

## --------------------------------------------------------------------------------

